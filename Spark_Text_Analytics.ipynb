{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark Text Analytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepds/sparkcourse/blob/master/Spark_Text_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWqBzOV6AeZ7",
        "colab_type": "code",
        "outputId": "39293fff-0b0c-47ac-e10c-5545736921dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!apt-get install openjdk-8-jdk\n",
        "#!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-8-jdk is already the newest version (8u222-b10-1ubuntu1~18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.4)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIGF1WK7FtY6",
        "colab_type": "code",
        "outputId": "ec13e26c-1ef9-4b49-b7ad-0f22ca3ea620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!java -version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.4\" 2019-07-16\n",
            "OpenJDK Runtime Environment (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctAV_2bHDFDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xojsYMqo-DV7",
        "colab_type": "code",
        "outputId": "6fb4e0b7-edf8-4a69-c44d-2133374b2e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9DKdweW-Gzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('abc').getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an6oA1Yz_2No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdrive/My Drive/Colab Notebooks/Spark/data/train.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXcO6d4EAImG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = spark.read.csv(path, header=True, inferSchema=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5LRRpHoAESV",
        "colab_type": "code",
        "outputId": "e3345683-a8c0-454f-ef25-d6104d157b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "drop_list = ['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
        "data = data.select([column for column in data.columns if column not in drop_list])\n",
        "data.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+\n",
            "|      Category|            Descript|\n",
            "+--------------+--------------------+\n",
            "|      WARRANTS|      WARRANT ARREST|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|\n",
            "+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIVo0MJYB6Xi",
        "colab_type": "code",
        "outputId": "7a025b26-6430-4728-f854-f0d8b63822ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Descript: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBIecpHoIrXw",
        "colab_type": "code",
        "outputId": "0ac610c1-0565-4721-d6fe-699d18bed820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "data.groupBy(\"Category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------+\n",
            "|            Category| count|\n",
            "+--------------------+------+\n",
            "|       LARCENY/THEFT|174900|\n",
            "|      OTHER OFFENSES|126182|\n",
            "|        NON-CRIMINAL| 92304|\n",
            "|             ASSAULT| 76876|\n",
            "|       DRUG/NARCOTIC| 53971|\n",
            "|       VEHICLE THEFT| 53781|\n",
            "|           VANDALISM| 44725|\n",
            "|            WARRANTS| 42214|\n",
            "|            BURGLARY| 36755|\n",
            "|      SUSPICIOUS OCC| 31414|\n",
            "|      MISSING PERSON| 25989|\n",
            "|             ROBBERY| 23000|\n",
            "|               FRAUD| 16679|\n",
            "|FORGERY/COUNTERFE...| 10609|\n",
            "|     SECONDARY CODES|  9985|\n",
            "|         WEAPON LAWS|  8555|\n",
            "|        PROSTITUTION|  7484|\n",
            "|            TRESPASS|  7326|\n",
            "|     STOLEN PROPERTY|  4540|\n",
            "|SEX OFFENSES FORC...|  4388|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjPXqzSVI0Wh",
        "colab_type": "code",
        "outputId": "ca83e6a1-034a-41eb-c7bb-db1ce740cd08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "data.groupBy(\"Descript\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            Descript|count|\n",
            "+--------------------+-----+\n",
            "|GRAND THEFT FROM ...|60022|\n",
            "|       LOST PROPERTY|31729|\n",
            "|             BATTERY|27441|\n",
            "|   STOLEN AUTOMOBILE|26897|\n",
            "|DRIVERS LICENSE, ...|26839|\n",
            "|      WARRANT ARREST|23754|\n",
            "|SUSPICIOUS OCCURR...|21891|\n",
            "|AIDED CASE, MENTA...|21497|\n",
            "|PETTY THEFT FROM ...|19771|\n",
            "|MALICIOUS MISCHIE...|17789|\n",
            "|   TRAFFIC VIOLATION|16471|\n",
            "|PETTY THEFT OF PR...|16196|\n",
            "|MALICIOUS MISCHIE...|15957|\n",
            "|THREATS AGAINST LIFE|14716|\n",
            "|      FOUND PROPERTY|12146|\n",
            "|ENROUTE TO OUTSID...|11470|\n",
            "|GRAND THEFT OF PR...|11010|\n",
            "|POSSESSION OF NAR...|10050|\n",
            "|PETTY THEFT FROM ...|10029|\n",
            "|PETTY THEFT SHOPL...| 9571|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTnl4SYyI6Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
        "\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"Descript\", outputCol=\"words\", pattern=\"\\\\W\") # tokenizer with regular expression\n",
        "\n",
        "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"]\n",
        "\n",
        "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
        "\n",
        "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghaT10-GJJYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) # inverse document frequency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOtoLGgANjDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?IDF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0uZwuC7CUob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meEvSLNALcSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
        "\n",
        "pipelineFit = pipeline.fit(data)\n",
        "\n",
        "dataset = pipelineFit.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eJD6Z1SHj8F",
        "colab_type": "code",
        "outputId": "829ae8a1-ff20-4047-be02-cf7f823fae9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "dataset.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|      Category|            Descript|               words|            filtered|         rawFeatures|            features|label|\n",
            "+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|      WARRANTS|      WARRANT ARREST|   [warrant, arrest]|   [warrant, arrest]|(10000,[2279,3942...|(10000,[2279,3942...|  7.0|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|[traffic, violati...|[traffic, violati...|(10000,[604,3942,...|(10000,[604,3942,...|  1.0|\n",
            "|OTHER OFFENSES|TRAFFIC VIOLATION...|[traffic, violati...|[traffic, violati...|(10000,[604,3942,...|(10000,[604,3942,...|  1.0|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|[grand, theft, fr...|[grand, theft, fr...|(10000,[274,713,3...|(10000,[274,713,3...|  0.0|\n",
            "| LARCENY/THEFT|GRAND THEFT FROM ...|[grand, theft, fr...|[grand, theft, fr...|(10000,[274,713,3...|(10000,[274,713,3...|  0.0|\n",
            "+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVxx_WQGJSBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NHOZaTsPhRJ",
        "colab_type": "code",
        "outputId": "41907956-b6aa-4dec-9ad5-d9085ece7dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Training Dataset Count: \" + str(trainingData.count()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset Count: 613959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feT_vaQ9PihE",
        "colab_type": "code",
        "outputId": "1a620168-2124-4444-83e7-f42b9f0ae898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Dataset Count: 264090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOifeyq7IAmf",
        "colab_type": "code",
        "outputId": "832d480c-ca9e-4bee-cb0c-e9cc4e0d4e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(trainingData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIAeNb5hJWS5",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QFQZL7NHykt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ls0aYrlHtJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "# Train model with Training Data\n",
        "lrModel = lr.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8DhS11tINkf",
        "colab_type": "code",
        "outputId": "f7d70ba5-536a-4568-b109-901d51bb5eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "|                      Descript|     Category|                   probability|label|prediction|\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "|THEFT, BICYCLE, <$50, NO SE...|LARCENY/THEFT|[0.8744258244000124,0.01995...|  0.0|       0.0|\n",
            "+------------------------------+-------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlV7rJ6dIWIu",
        "colab_type": "code",
        "outputId": "d9ba19cf-45ed-4f0a-8396-ad2298908aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9722666656693439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjNyummSIyjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6l3XxrgIymx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, [0.1, 0.3, 0.5])\n",
        "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2])\n",
        "             .build())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGdJzn0ZJLo9",
        "colab_type": "code",
        "outputId": "e9e6d93f-a2e7-4922-9c1c-cede0361a414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
        "cvModel = cv.fit(trainingData)\n",
        "\n",
        "predictions = cvModel.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2c8699388390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVslaLaJLVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSIUeVDPJPhi",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ugjYUlALuWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(numTrees=100, maxDepth=3, labelCol=\"label\", featuresCol=\"features\", maxBins = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOB1Ur4lL7vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfModel = rf.fit(trainingData)\n",
        "predictions = rfModel.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IK3rZrOL71Q",
        "colab_type": "code",
        "outputId": "b4666172-1617-4fc0-bb57-6d0ca79cf0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------+-------------+------------------------------+-----+----------+\n",
            "|                    Descript|     Category|                   probability|label|prediction|\n",
            "+----------------------------+-------------+------------------------------+-----+----------+\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "|GRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.5608854046412892,0.07575...|  0.0|       0.0|\n",
            "+----------------------------+-------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjfovlLAMP9O",
        "colab_type": "code",
        "outputId": "a231dab1-943a-408e-ad93-faabd271d5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6039479727355171"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507Y_PqJJsaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(rf.numTrees, [50, 100, 200]) \n",
        "             .addGrid(rf.maxDepth, [3, 4, 5]) \n",
        "#            .addGrid(rf.maxBins, [24, 32, 40])\n",
        "             .build())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47yG9kZeJs0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CrossValidator(estimator=rf, \\\n",
        "                    estimatorParamMaps=paramGrid, \\\n",
        "                    evaluator=evaluator, \\\n",
        "                    numFolds=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP2KJP6jI85j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvModel = cv.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifn24PYKI-Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = cvModel.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb8mtigTJwf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYZy6D66Mko5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}